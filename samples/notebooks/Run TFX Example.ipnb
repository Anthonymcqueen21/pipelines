{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFX on KubeFlow Pipelines Example\n",
    "\n",
    "### Install TFX and KFP packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tfx=0.13.0rc0\n",
    "!pip3 install https://storage.googleapis.com/ml-pipeline/release/0.1.10/kfp.tar.gz --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the TFX repo with sample pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tensorflow/tfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the trainer code to a storage bucket \n",
    "!gsutil cp tfx/examples/chicago_taxi_pipeline/taxi_utils.py gs://my-bucket/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the TFX pipeline example\n",
    "\n",
    "Reload this cell by replacing the content with\n",
    "```\n",
    "%load tfx/examples/chicago_taxi_pipeline/taxi_pipeline_kubeflow_large.py\n",
    "```\n",
    "and adding on top\n",
    "```\n",
    "%%writefile my_taxi_pipeline_kubeflow_large.py\n",
    "```\n",
    "\n",
    "Configure:\n",
    "- GCS storage bucket name (replace my-bucket)\n",
    "- GCP project ID (replace my-gcp-project)\n",
    "- Make sure the path to the taxi_utils.py is correct\n",
    "- Set the limit on the BigQuery query. The dataset has 100M rows, which can take time to process. Set it to 20000 to run an sample test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile my_taxi_pipeline_kubeflow_large.py\n",
    "\"\"\"Chicago Taxi example using TFX DSL on Kubeflow.\"\"\"\n",
    "# Copyright 2019 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# TODO(ajaygopinathan): Rename this file to taxi_pipeline_kubeflow.py\n",
    "import os\n",
    "from tfx.components.evaluator.component import Evaluator\n",
    "from tfx.components.example_gen.big_query_example_gen.component import BigQueryExampleGen\n",
    "from tfx.components.example_validator.component import ExampleValidator\n",
    "from tfx.components.model_validator.component import ModelValidator\n",
    "from tfx.components.pusher.component import Pusher\n",
    "from tfx.components.schema_gen.component import SchemaGen\n",
    "from tfx.components.statistics_gen.component import StatisticsGen\n",
    "from tfx.components.trainer.component import Trainer\n",
    "from tfx.components.transform.component import Transform\n",
    "from tfx.orchestration.kubeflow.runner import KubeflowRunner as TfxRunner\n",
    "from tfx.orchestration.pipeline import PipelineDecorator\n",
    "from tfx.proto import evaluator_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "\n",
    "# Cloud storage\n",
    "_output_bucket = 'gs://my-bucket'\n",
    "# GCP project id to use.\n",
    "_project_id = 'my-gcp-project'\n",
    "# Helper functions for the taxi pipeline: estimator and preprocessing_fn. Copy\n",
    "# this from the current directory to a GCS bucket and update the location\n",
    "# below.\n",
    "_taxi_utils = os.path.join(_output_bucket, 'taxi_utils.py')\n",
    "# Path which can be listened by model server. Pusher will output model here.\n",
    "_serving_model_dir = os.path.join(_output_bucket, 'serving_model/taxi_bigquery')\n",
    "# Root for all pipeline output.\n",
    "_pipeline_root = os.path.join(_output_bucket, 'output')\n",
    "\n",
    "# Region to use for Dataflow jobs and CMLE training.\n",
    "#   Dataflow: https://cloud.google.com/dataflow/docs/concepts/regional-endpoints\n",
    "#   CMLE:     https://cloud.google.com/ml-engine/docs/tensorflow/regions\n",
    "_gcp_region = 'us-central1'\n",
    "\n",
    "_cmle_training_args = {\n",
    "    'pythonModule': None,  # Will be populated by TFX\n",
    "    'args': None,  # Will be populated by TFX\n",
    "    'region': _gcp_region,\n",
    "    'jobDir': os.path.join(_output_bucket, 'tmp'),\n",
    "    'runtimeVersion': '1.12',\n",
    "    'pythonVersion': '2.7',\n",
    "    'project': _project_id,\n",
    "}\n",
    "\n",
    "\n",
    "@PipelineDecorator(\n",
    "    pipeline_name='chicago_taxi_pipeline_kubeflow_large',\n",
    "    log_root='/var/tmp/tfx/logs',\n",
    "    pipeline_root=_pipeline_root,\n",
    "    additional_pipeline_args={\n",
    "        'beam_pipeline_args': [\n",
    "            '--runner=DataflowRunner', '--experiments=shuffle_mode=auto',\n",
    "            '--project=' + _project_id,\n",
    "            '--temp_location=' + os.path.join(_output_bucket, 'tmp'),\n",
    "            '--region=' + _gcp_region,\n",
    "        ],\n",
    "    })\n",
    "def _create_pipeline():\n",
    "  \"\"\"Implements the chicago taxi pipeline with TFX.\"\"\"\n",
    "  query = \"\"\"\n",
    "          SELECT\n",
    "            pickup_community_area,\n",
    "            fare,\n",
    "            EXTRACT(MONTH FROM trip_start_timestamp) AS trip_start_month,\n",
    "            EXTRACT(HOUR FROM trip_start_timestamp) AS trip_start_hour,\n",
    "            EXTRACT(DAYOFWEEK FROM trip_start_timestamp) AS trip_start_day,\n",
    "            UNIX_SECONDS(trip_start_timestamp) AS trip_start_timestamp,\n",
    "            pickup_latitude,\n",
    "            pickup_longitude,\n",
    "            dropoff_latitude,\n",
    "            dropoff_longitude,\n",
    "            trip_miles,\n",
    "            pickup_census_tract,\n",
    "            dropoff_census_tract,\n",
    "            payment_type,\n",
    "            company,\n",
    "            trip_seconds,\n",
    "            dropoff_community_area,\n",
    "            tips\n",
    "          FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "          ORDER BY trip_start_timestamp\n",
    "          LIMIT 50000\"\"\"  # 100 Million.\n",
    "\n",
    "  # Brings data into the pipeline or otherwise joins/converts training data.\n",
    "  example_gen = BigQueryExampleGen(query=query)\n",
    "\n",
    "  # Computes statistics over data for visualization and example validation.\n",
    "  statistics_gen = StatisticsGen(input_data=example_gen.outputs.examples)\n",
    "\n",
    "  # Generates schema based on statistics files.\n",
    "  infer_schema = SchemaGen(stats=statistics_gen.outputs.output)\n",
    "\n",
    "  # Performs anomaly detection based on statistics and data schema.\n",
    "  validate_stats = ExampleValidator(\n",
    "      stats=statistics_gen.outputs.output, schema=infer_schema.outputs.output)\n",
    "\n",
    "  # Performs transformations and feature engineering in training and serving.\n",
    "  transform = Transform(\n",
    "      input_data=example_gen.outputs.examples,\n",
    "      schema=infer_schema.outputs.output,\n",
    "      module_file=_taxi_utils)\n",
    "\n",
    "  # Uses user-provided Python function that implements a model using TF-Learn.\n",
    "  trainer = Trainer(\n",
    "      module_file=_taxi_utils,\n",
    "      transformed_examples=transform.outputs.transformed_examples,\n",
    "      schema=infer_schema.outputs.output,\n",
    "      transform_output=transform.outputs.transform_output,\n",
    "      train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
    "      eval_args=trainer_pb2.EvalArgs(num_steps=5000),\n",
    "      custom_config={'cmle_training_args': _cmle_training_args})\n",
    "\n",
    "  # Uses TFMA to compute a evaluation statistics over features of a model.\n",
    "  model_analyzer = Evaluator(\n",
    "      examples=example_gen.outputs.examples,\n",
    "      model_exports=trainer.outputs.output,\n",
    "      feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n",
    "          evaluator_pb2.SingleSlicingSpec(\n",
    "              column_for_slicing=['trip_start_hour'])\n",
    "      ]))\n",
    "\n",
    "  # Performs quality validation of a candidate model (compared to a baseline).\n",
    "  model_validator = ModelValidator(\n",
    "      examples=example_gen.outputs.examples, model=trainer.outputs.output)\n",
    "\n",
    "  # Checks whether the model passed the validation steps and pushes the model\n",
    "  # to a file destination if check passed.\n",
    "  pusher = Pusher(\n",
    "      model_export=trainer.outputs.output,\n",
    "      model_blessing=model_validator.outputs.blessing,\n",
    "      push_destination=pusher_pb2.PushDestination(\n",
    "          filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "              base_directory=_serving_model_dir)))\n",
    "\n",
    "  return [\n",
    "      example_gen, statistics_gen, infer_schema, validate_stats, transform,\n",
    "      trainer, model_analyzer, model_validator, pusher\n",
    "  ]\n",
    "\n",
    "\n",
    "pipeline = TfxRunner().run(_create_pipeline())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the pipeline and submit a run to the Kubeflow cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the pipeline compilation\n",
    "!python my_taxi_pipeline_kubeflow_large.py\n",
    "#it should create file chicago_taxi_pipeline_kubeflow_large.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create a new experiment\n",
    "import kfp\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(\"TFX Examples\")\n",
    "pipeline_filename = \"chicago_taxi_pipeline_kubeflow_large.tar.gz\"\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = 'Run 1'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, {})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
